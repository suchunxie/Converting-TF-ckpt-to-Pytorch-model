{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Convert_ckpt_to_Pytorch_model.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPKd0Ni5jS+6DPGPSxcgkOb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Tutorial of converting TF-ckpt to Pytorch model**"],"metadata":{"id":"_kLbQTOxK35c"}},{"cell_type":"markdown","source":["**Environment:**\n","- Anaconda\n","- Python: Python 3.7.13\n","- Tensorflow-gpu: 2.3.0\n","- cudnn: 7.6.5\n","- transformers: 4.18.0\n","- cudatoolkit: 10.2.89 (will be installed when installing pytorch )\n","\n"],"metadata":{"id":"CWGjh4UNK80g"}},{"cell_type":"code","source":["# Error loading \"D:\\Xie\\anaconda3\\envs\\model_convert\\lib\\site-packages\\torch\\lib\\c10_cuda.dll\" or one of its dependencies. \n","conda install pytorch==1.10.1 torchvision==0.11.2 torchaudio==0.10.1 cudatoolkit=10.2 -c pytorch"],"metadata":{"id":"T0wIP_dVNebm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Install Pytorch \n","pip install torch==1.5.0+cu101 torchvision==0.6.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html"],"metadata":{"id":"ukbVH1iIN9RI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Test Pytorch, create [test_pytorch.py] with the following code:\n","import torch\n","x = torch.rand(5, 3)\n","print(x)"],"metadata":{"id":"R046UokbOD5z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["python test_pytorch.py"],"metadata":{"id":"_2gPzgFBOQTl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- Results will be as follow if successed:\n","      tensor([[0.4234, 0.1579, 0.2756],\n","        [0.2334, 0.8166, 0.8440],\n","        [0.4211, 0.7514, 0.8699],\n","        [0.3524, 0.8092, 0.6740],\n","        [0.4994, 0.1447, 0.2861]])\n"],"metadata":{"id":"6j-uUxMlOeLb"}},{"cell_type":"markdown","source":["**Notes:**\n","- tf_checkpint should include filename like below, rename is necessary or error occurs.\n","    - :bert_model.ckpt.data-00000-of-00001\n","    - :bert_model.ckpt.index\n"],"metadata":{"id":"AmfgdGInPs_m"}},{"cell_type":"code","source":["# Run converting.\n","transformers-cli convert --model_type=bert --tf_checkpoint D:\\Xie\\Wordpiece_model\\checkpoints\\convert\\bert_model.ckpt --config D:\\Xie\\Wordpiece_model\\checkpoints\\convert\\config\\config.json --pytorch_dump_output D:\\Xie\\Wordpiece_model\\checkpoints\\convert\\pytorch_model.bin"],"metadata":{"id":"2qRz_v5VLPS0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Meet errors:**\n","- Loading TF weight save_counter/.ATTRIBUTES/VARIABLE_VALUE with shape []\n","Skipping _CHECKPOINTABLE_OBJECT_GRAPH\n","Traceback (most recent call last):\n"," -  File \"D:\\Xie\\anaconda3\\envs\\model_convert\\Scripts\\transformers-cli-script.py\", line 10, in <module>\n","    sys.exit(main())\n"," -  File \"D:\\Xie\\anaconda3\\envs\\model_convert\\lib\\site-packages\\transformers\\commands\\transformers_cli.py\", line 53, in main\n","    service.run()\n"," -   File \"D:\\Xie\\anaconda3\\envs\\model_convert\\lib\\site-packages\\transformers\\commands\\convert.py\", line 104, in run\n","    convert_tf_checkpoint_to_pytorch(self._tf_checkpoint, self._config, self_pytorch_dump_output)\n"," -   File \"D:\\Xie\\anaconda3\\envs\\model_convert\\lib\\site-packages\\transformers\\models\\bert\\convert_bert_original_tf_checkpoint_to_pytorch.py\", line 36, in convert_tf_checkpoint_to_pytorch\n","    load_tf_weights_in_bert(model, config, tf_checkpoint_path)\n","  File \"D:\\Xie\\anaconda3\\envs\\model_convert\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\", line 156, in load_tf_weights_in_bert\n","    if pointer.shape != array.shape:\n","  File \"D:\\Xie\\anaconda3\\envs\\model_convert\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 594, in __getattr__\n","    type(self).__name__, name))\n","AttributeError: 'BertForPreTraining' object has no attribute 'shape'"],"metadata":{"id":"K2bQO1yqRRyS"}},{"cell_type":"markdown","source":["cd **modeling_bert.py**\n","- D:\\Xie\\anaconda3\\envs\\model_convert\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\n","\n","Change the lines from 93-174"],"metadata":{"id":"0sL1XASMP38P"}},{"cell_type":"code","source":["# the replace code\n","def load_tf_weights_in_bert(model, config, tf_checkpoint_path):\n","    try:\n","        import re\n","        import numpy as np\n","        import tensorflow as tf\n","    except ImportError:\n","        logger.error(\n","            \"Loading a TensorFlow model in PyTorch, requires TensorFlow to be installed. Please see \"\n","            \"https://www.tensorflow.org/install/ for installation instructions.\"\n","        )\n","        raise\n","    tf_path = os.path.abspath(tf_checkpoint_path)\n","    logger.info(f\"Converting TensorFlow checkpoint from {tf_path}\")\n","    # Load weights from TF model\n","    init_vars = tf.train.list_variables(tf_path)\n","    names = []\n","    arrays = []\n","    for name, shape in init_vars:\n","        logger.info(f\"Loading TF weight {name} with shape {shape}\")\n","        array = tf.train.load_variable(tf_path, name)\n","        names.append(name)\n","        arrays.append(array)\n","    for name, array in zip(names, arrays):\n","        name = name.split(\"/\")\n","        # adam_v and adam_m are variables used in AdamWeightDecayOptimizer to calculated m and v\n","        # which are not required for using pretrained model\n","        if any(\n","            [\"adam_v\", \"adam_m\", \"global_step\", \"bad_steps\", \"global_step\", \"good_steps\", \"loss_scale\",\n","                     \"AdamWeightDecayOptimizer\", \"AdamWeightDecayOptimizer_1\", \"save_counter\", \".OPTIMIZER_SLOT\"] for n in name) or \\\n","                name[0] == \"optimizer\":\n","        #     n in [\"adam_v\", \"adam_m\", \"AdamWeightDecayOptimizer\", \"AdamWeightDecayOptimizer_1\", \"global_step\"]\n","        #     for n in name\n","        # ):\n","            logger.info(f\"Skipping {'/'.join(name)}\")\n","            continue\n","        if \".OPTIMIZER_SLOT\" in name:\n","            idx = name.index(\".OPTIMIZER_SLOT\")\n","            name = name[:idx]\n","        elif \".ATTRIBUTES\" in name:\n","            idx = name.index(\".ATTRIBUTES\")\n","            name = name[:idx]\n","        print(name)\n","        pointer = model\n","        for m_name in name:\n","            if re.fullmatch(r\"[A-Za-z]+_\\d+\", m_name):\n","                scope_names = re.split(r\"_(\\d+)\", m_name)\n","            else:\n","                scope_names = [m_name]\n","            if scope_names[0] == \"kernel\" or scope_names[0] == \"gamma\":\n","                pointer = getattr(pointer, \"weight\")\n","            elif scope_names[0] == \"output_bias\" or scope_names[0] == \"beta\":\n","                pointer = getattr(pointer, \"bias\")\n","            elif scope_names[0] == \"output_weights\":\n","                pointer = getattr(pointer, \"weight\")\n","            elif scope_names[0] == \"squad\":\n","                pointer = getattr(pointer, \"classifier\")\n","            elif scope_names[0] == \"dense_output\" or scope_names[0] == \"bert_output\":\n","                pointer = getattr(pointer, \"output\")\n","            elif scope_names[0] == \"self_attention\":\n","                pointer = getattr(pointer, \"self\")\n","            else:\n","                try:\n","                    pointer = getattr(pointer, scope_names[0])\n","                except AttributeError:\n","                    logger.info(\"Skipping {}\".format(\"/\".join(name)))\n","                    continue\n","            if len(scope_names) >= 2:\n","                num = int(scope_names[1])\n","                pointer = pointer[num]\n","        if m_name[-11:] == \"_embeddings\":\n","            pointer = getattr(pointer, \"weight\")\n","        elif m_name == \"kernel\" or m_name == \"gamma\" or m_name == \"output_weights\":\n","            array = np.transpose(array)\n","        # try:\n","        #     if pointer.shape != array.shape:\n","        #         raise ValueError(f\"Pointer shape {pointer.shape} and array shape {array.shape} mismatched\")\n","        # except AssertionError as e:\n","        #     e.args += (pointer.shape, array.shape)\n","        #     raise\n","        logger.info(f\"Initialize PyTorch weight {name}\")\n","        pointer.data = torch.from_numpy(array)\n","    return model"],"metadata":{"id":"h9HkoRaYS2sU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# run convert again\n","transformers-cli convert --model_type=bert --tf_checkpoint D:\\Xie\\Wordpiece_model\\checkpoints\\convert\\bert_model.ckpt --config D:\\Xie\\Wordpiece_model\\checkpoints\\convert\\config\\config.json --pytorch_dump_output D:\\Xie\\Wordpiece_model\\checkpoints\\convert\\pytorch_model.bin"],"metadata":{"id":"20JfzqMOTEnt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Results**\n","- Skipping model/layer_with_weights-9/_output_layer_norm/beta/.ATTRIBUTES/VARIABLE_VALUE\n","- Skipping model/layer_with_weights-9/_output_layer_norm/gamma/.ATTRIBUTES/VARIABLE_VALUE\n","- Skipping save_counter/.ATTRIBUTES/VARIABLE_VALUE\n","- Save PyTorch model to D:\\Xie\\Wordpiece_model\\checkpoints\\convert\\pytorch_model.bin"],"metadata":{"id":"Jx61Qg0STLaF"}},{"cell_type":"markdown","source":["**Referenced:**\n","- [Huggingface - Converting Tensorflow Checkpoints](https://huggingface.co/docs/transformers/converting_tensorflow_models#t5)\n","- [Pytorch is not available with Cuda 10.1](https://qiita.com/musicangora/items/efea21b051ecbfd0b500) \n","- [BertForPreTraining' object has no attribute 'shape'](https://github.com/huggingface/transformers/issues/393)\n","\n"],"metadata":{"id":"MDnTN8JiTjo2"}}]}